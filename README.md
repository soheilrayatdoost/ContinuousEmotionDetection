# ContinuousEmotionDetection
Analysis of EEG Signals and Facial Expressions for Continuous Emotion Detection code

You need to inatall KERAS with tensorflow to run the code



M. Soleymani, S. Asghari-Esfeden, Y. Fu and M. Pantic, "Analysis of EEG Signals and Facial Expressions for Continuous Emotion Detection," in IEEE Transactions on Affective Computing, vol. 7, no. 1, pp. 17-28, 1 Jan.-March 2016.
doi: 10.1109/TAFFC.2015.2436926

keywords: {electroencephalography;emotion recognition;face recognition;random processes;recurrent neural nets;video signal processing;EEG signal analysis;facial expression analysis;continuous emotion detection;time varying affective phenomena;elicit emotions;viewer emotion detection;video emotional traces;video viewer emotion detection;electroencephalogram signals;physiological responses;negative emotions;positive emotions;valence annotation;arousal dimension;long-short-term-memory recurrent neural networks;LSTM-RNN;continuous conditional random fields;CCRF;facial muscle activities;statistical analysis;Videos;Electroencephalography;Feature extraction;Motion pictures;Databases;Tagging;Recurrent neural networks;Affect;EEG;facial expressions;video highlight detection;implicit tagging;Affect;EEG;facial expressions;video highlight detection;implicit tagging},

URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7112127&isnumber=7420758
