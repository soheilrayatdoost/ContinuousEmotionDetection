# ContinuousEmotionDetection
Analysis of EEG Signals and Facial Expressions for Continuous Emotion Detection code

You need to install KERAS with tensorflow to run the code



M. Soleymani, S. Asghari-Esfeden, Y. Fu and M. Pantic, "Analysis of EEG Signals and Facial Expressions for Continuous Emotion Detection," in IEEE Transactions on Affective Computing, vol. 7, no. 1, pp. 17-28, 1 Jan.-March 2016.
doi: 10.1109/TAFFC.2015.2436926

keywords: {electroencephalography; emotion recognition; face recognition; random processes; recurrent neural nets; video signal processing; EEG signal analysis; facial expression analysis; continuous emotion detection; time varying affective phenomena; elicit emotions; viewer emotion detection; video emotional traces; video viewer emotion detection; electroencephalogram signals; physiological responses; negative emotions; positive emotions; valence annotation; arousal dimension; long-short-term-memory recurrent neural networks; LSTM-RNN; continuous conditional random fields; CCRF; facial muscle activities; statistical analysis; Videos; Electroencephalography; Feature extraction; Motion pictures; Databases; Tagging; Recurrent neural networks; Affect; EEG; facial expressions; video highlight detection; implicit tagging; Affect;EEG; facial expressions; video highlight detection; implicit tagging},

URL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7112127&isnumber=7420758
